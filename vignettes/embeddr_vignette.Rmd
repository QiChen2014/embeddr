---
title: "Laplacian eigenmaps & principal curves for pseudotemporal ordering of single-cell gene expression"
author: "Kieran Campbell"
date: "March 2015"
output:
  html_document:
    fig_align: center
    fig_height: 3.8
    fig_width: 5
  pdf_document: default
---

Here we show how `embeddr` (= spectral embedding + principal curves) can be used for pseudotemporal ordering of single-cell gene expression data using the [monocle](http://cole-trapnell-lab.github.io/monocle-release/) dataset.

```{r load-all, message=FALSE, warning=FALSE}
library(monocle)
library(devtools)
library(reshape2)
library(plyr)
library(dplyr)
library(ggplot2)
library(ggthemes)
load_all('..')
data(HSMM)

```

First we go through cleaning the monocle dataset and selecting for marker genes only:

```{r clean-monocle, cache=TRUE}
marker_genes <- row.names(subset(fData(HSMM),
                                 gene_short_name %in% c("MEF2C", "MEF2D", "MYF5", "ANPEP", "PDGFRA",
                  "MYOG", "TPM1", "TPM2", "MYH2", "MYH3", "NCAM1",
                  "CDK1", "CDK2", "CCNB1", "CCNB2", "CCND1", "CCNA")))
x <- log(exprs(HSMM[marker_genes,]) + 1)
x <- t(scale(t(x)))
dim(x)
```

### Laplacian eigenmaps
Laplacian eigenmaps require the specification of a nearest-neighbor graph. We can do this using `embeddr::weighted_graph()` using the default options of 20 nearest neighbours. Other options for creating the graph (such as distance measures and heat kernels) are also available.

```{r create-graph, cache=TRUE}
W <- weighted_graph(x)
```

Then we can use `embeddr::laplacian_eigenmap` for the dimensionality reduction. By default this uses the normalized graph laplacian, though the unnormalised laplacian can also be used (see here for details).

```{r laplacian-eigenmap, cache=TRUE, fig.align='center'}
M <- laplacian_eigenmap(W)
plot_embedding(M)
```

The function `embeddr::plot_embedding` can be used at any time on the appropriate `data.frame` objects and will display all relevant information. We can start by seeing where the different inferred states from the monocle dataset fall on our embedding:

```{r monocle-state, fig.align='center', cache=TRUE}
HSMM <- setOrderingFilter(HSMM, marker_genes)
HSMM <- reduceDimension(HSMM, use_irlba = F)
HSMM <- orderCells(HSMM, num_paths=2, reverse=F)
M$monocle_state <- pData(HSMM)$State
plot_embedding(M, color_by = 'monocle_state')
```

So there appears to be reasonable correspondance between the monocle clusters and natural clusters in our data. The `embeddr::cluster_embedding` function applies k-means clustering to the dataset:

```{r cluster-embedding, fig.align='center', cache=TRUE, message=FALSE}
set.seed(123)
M <- cluster_embedding(M, k=3, method='kmeans')
plot_embedding(M)
```

### Selecting genes for the embedding

In standard manifold learning problems it is recommended that each feature is appropriately scaled to have mean 0 and variance 1. Since laplacian eigenmaps depend only on the distance between data points, scaling the features is equivalent to treating the variance in each gene equally no matter how large or small it was originally. As a result, the variance in genes that don't truly vary that much (such as housekeeping genes) is as important as the genes that really do vary with the biological process of interest, adding much noise to the process.

There are several ways to get round this problem. We can choose genes we a priori know vary with the biological process as we have done above (where the genes chosen are those associated with muscle development). An alternative is to choose genes whose coefficient of variation (CV2) is above some threshold or in a particular percentile:

```{r cv2, cache=TRUE, fig.align='center'}
x <- t(log10(exprs(HSMM) + 1))
x_mean <- colMeans(x)
x_var <- colVars(x)
genes_for_fit <- x_mean > 0.3
CV2 <- x_var[genes_for_fit] / (x_mean[genes_for_fit])^2
df_fit <- data.frame(m = x_mean[genes_for_fit], CV2 = CV2)
fit_loglin <- nls(CV2 ~ a * 10^(-k * m), data = df_fit, start=c(a=5, k=1)) 
ak <- coef(fit_loglin)
f <- function(x) ak[1] * 10^(-ak[2] * x) 
genes_for_embedding <- (CV2 > 4 * predict(fit_loglin))
df_fit$for_embedding <- as.factor(genes_for_embedding)
ggplot(df_fit, aes(x=m, y=CV2, color = for_embedding)) + geom_point() +
  theme_bw() + xlab('Mean') + ylab('CV2') + scale_color_fivethirtyeight() +
  stat_function(fun=f, color='black')
```

Once we have picked the genes we want to use for the embedding, we scale them to treat them as equal to avoid high magnitude outliers driving the embedding:

```{r embedding_highmag, cache=TRUE, fig.align='center', fig.width=6.5, fig.height=4.5}
xe <- t((x[,names(which(genes_for_embedding))]))
W <- weighted_graph(xe)
Me <- laplacian_eigenmap(W)
Me$monocle_state <- M$monocle_state
plot_embedding(Me, color_by = 'monocle_state')
```

We can also cluster the embedding using kmeans and plot:
```{r clust_emb, cache=TRUE, fig.align='center', fig.width=6, fig.height=4.5}
set.seed(123)
Me <- cluster_embedding(Me, k=3)
plot_embedding(Me)
M <- Me
```

Finally, we want to check the method is different to a more primitive technique such as PCA alone:

```{r pca, cache=TRUE, fig.align='center', fig.width=6, fig.height=4.5}
pca <- princomp(t(xe))
df_pca <- data.frame(x1 = pca$scores[,1], x2 = pca$scores[,2], monocle_state = Me$monocle_state)
ggplot(df_pca, aes(x=x2, y=x1, color=monocle_state)) + geom_point() + 
  theme_bw() + scale_color_fivethirtyeight()
```

### Pseudotime fitting
In the `monocle` paper they show that groups 1 & 3 correspond to differentiating cells while group 2 is contamination. We can separate off groups 1 & 3, fit the pseudotime trajectories and plot:

```{r fit-pseudotime, fig.align='center', cache=TRUE}
Mp <- fit_pseudotime(Me, clusters=c(1,3))
plot_embedding(Mp)
```

Each `embeddr` function works similar to `dplyr` in that it takes the original matrix, modifies it and returns it. We can see the result of all our function calls so far:

```{r show-M, cache=TRUE}
head(Mp)
```
The `pseudotime` variable is a measure of pseudotime (in fact, the arc-length from the beginning of the curve). The variables `trajectory_1` and `trajectory_2` show the projections of each cell onto the curve.

We can also compare our pseudotime with that of `monocle`:

```{r comp-mon, cache=TRUE, fig.align='center', fig.width=4, fig.height=4}
in_state13 <- M$cell_id[M$cluster %in% c(1,3)]
monocle_df <- filter(pData(HSMM), cell_id %in% in_state13)

qplot(arrange(monocle_df, cell_id)$Pseudotime, arrange(Mp, cell_id)$pseudotime) +
  theme_bw() + xlab('Monocle pseudotime') + ylab('embeddr pseudotime')
```

So there is good correspondence between the `monocle` and `embeddr` pseudotimes, though it appears that the `embeddr` version goes in the wrong direction. Pseudotimes are equivalent up to parity and scaling transformations (which is perhaps more philosophical than it sounds), so we can use the `embeddr::reverse_pseudotime` function to make the pseudotimes 'run' in the same direction:

```{r reverse-pseudotime, fig.align='center', fig.width=4, fig.height=4}
Mp <- reverse_pseudotime(Mp)
qplot(arrange(monocle_df, cell_id)$Pseudotime, arrange(Mp, cell_id)$pseudotime) +
  theme_bw() + xlab('Monocle pseudotime') + ylab('embeddr pseudotime')
```

The overall correlation between the two pseudotime trajectories is `r format(round(cor(arrange(monocle_df, cell_id)$Pseudotime, arrange(Mp, cell_id)$pseudotime),2), nsmall=2)`, which is pretty good. 


### Plotting genes in pseudotime

To plot the genes in pseudotime we need to provide the original gene values for the cells in clusters 1 & 3:

```{r plot-prep, cache=TRUE, fig.align='center', fig.width=5, fig.height=5}
xp <- select(data.frame(t(x)), one_of(Mp$cell_id))

genes_to_plot <- row.names(subset(fData(HSMM), 
                                  gene_short_name %in% c("CDK1", "MEF2C", "MYH3", "MYOG")))
gene_short_names <- fData(HSMM)[genes_to_plot,]$gene_short_name

plot_in_pseudotime(Mp, xp, genes_to_plot, gene_short_names)
```

which is largely similar to the monocle equivalent.

We can also plot a heatmap of all the genes in pseudotime:

```{r heatmap, fig.align='center', fig.width=8.5,fig.height=6, message=FALSE}
plot_heatmap(Mp, x)
```


### Robustness to choice of nearest neighbours

We can also show that the overall shape of the embedding is robust to a varying choice of nearest neighbours:

```{r neighbour-choice, fig.align='center', fig.width=8, fig.height=6, cache=TRUE}
x <- xe
nns <- c(15, 20, 25, 30, 35, 40)
embeddings <- ldply(nns, function(i) laplacian_eigenmap(weighted_graph(x, nn = i)))
embeddings$nn <- rep(nns, each = dim(x)[2])
embeddings$monocle_state  <- rep(M$monocle_state, times = length(nns))

ggplot(data=embeddings, aes(x=component_1, y=component_2, color=monocle_state)) + geom_point() +
  theme_bw() + facet_wrap(~ nn) +
  ggtitle('Overall shape for variety of nearest neighbours')
```

### Unravelling the contaminated cells

In the original monocle dataset, only a small number of cells were assigned to group 3 ('interstitial mesenchymal cell'). However, our re-analysis suggests it is somewhat a larger with `r sum(M$cluster == 2)` cells in total. These cells were identified as mesenchymal cells as they expressed PDGFRA and SPHK1 in high abundances. We can look to see whether in our cell set we've identified more cells that are potentially contamination:

```{r cont1, fig.align='center', cache=TRUE}
M_cont <- filter(M, cluster == 2)
M_cont$cluster <- 3
print(table(M_cont$cluster, M_cont$monocle_state))
```
So the classifications agree on 60 of the cells but disagree on the other 51. Note that the differences in classification are really driven by the reduced geometry rather than the classification algorithm. 

What we'd like to do is see how the gene markers compare when considering the contamined cells identified by monocle, the contaminated cells we identify, and all other cells:
```{r cont2, fig.align='center', cache=TRUE, message=FALSE, warning=FALSE}
M$agree_contamination <- apply(M, 1, function(x) {
  if(x['monocle_state'] == 3 & x['cluster'] == 2) {
     return('agree_cont')
  } else if(x['monocle_state'] != 3 & x['cluster'] == 2) {
    return('embeddr_only')
  }  else if(x['monocle_state'] == 3 & x['cluster'] != 3) {
      return('monocle_only')
  } else {
    return('non_cont')
  } 
})

cont_genes <- row.names(subset(fData(HSMM),  gene_short_name %in% c("PDGFRA", "SPHK1")))
short_names <- fData(HSMM)[cont_genes,]$gene_short_name
y <- log(exprs(HSMM[cont_genes,]) + 1)
y <- scale(t(y))
y <- data.frame(y)
y <- melt(y, variable.name='gene', value.name='counts')
y$gene <- mapvalues(y$gene, from = cont_genes, to = short_names)
y$agree_contamination <- M$agree_contamination
ggplot(y, aes(x=factor(agree_contamination), color=factor(agree_contamination), y=counts)) + 
  facet_wrap(~gene) + 
  geom_boxplot() + theme_bw() + xlab('') +
  scale_x_discrete(labels=c('Contamination agree','Embeddr only','Monocle only','No contamination')) +
  theme(axis.text.x = element_text(angle = -90, hjust=0)) + scale_color_fivethirtyeight(guide=FALSE)
```

So it looks like they might have missed a few cells expressing PDGFRA and SPHK1. We can also plot the markers in the embedded space, as per in the original paper:
```{r markers-in-space, cache=T, fig.width=9, fig.height=8, fig.align='center'}
cont_genes <- row.names(subset(fData(HSMM),  gene_short_name %in% c("CDK1", "MYOG", "PDGFRA", 
                                                                    "SPHK1", "MYF5", "NCAM1")))
short_names <- fData(HSMM)[cont_genes,]$gene_short_name
y <- log(exprs(HSMM[cont_genes,]) + 1)
y <- t(y)
y <- data.frame(y)
M_y <- cbind(M, y)
M_y_melted <- melt(M_y, id.vars=names(M), variable.name='gene', value.name='count')
M_y_melted$gene <- mapvalues(M_y_melted$gene, from = cont_genes, to = short_names)
ggplot(M_y_melted, aes(x=component_1, y=component_2, size=count, color=factor(cluster))) + 
  geom_point(alpha=0.6) + facet_wrap(~ gene) + theme_bw() +
  scale_color_fivethirtyeight(name='cluster') + scale_size_continuous(name='log10(count)')
```


